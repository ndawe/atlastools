#!/usr/bin/env python

from argparse import ArgumentParser

parser = ArgumentParser(usage="%(prog)s [args] file1,file2,file3...")
parser.add_argument('-v', '--verbose', action="store_true",
                  help="verbose", default=False)
parser.add_argument('-e', '--events', type=int,
                  help="number of events to process", default=-1)
parser.add_argument('-d', '--dataset',
                  help="name of dataset being processed", required=True)
parser.add_argument('-m', '--metadata',
                  help="YAML file containing dataset definitions", required=True)
parser.add_argument('-s', '--student',
                  help="the file (excluding .py extension) containing a"
                       "class of the same name inheriting from rootpy.batch.Student", required=True)
parser.add_argument('files', nargs='+')
args, user_args = parser.parse_known_args()

import sys
import os
import ROOT
import glob
from atlastools.batch import ATLASSupervisor
from atlastools import datasets
from atlastools.datasets import ATLASFileset
from atlastools import utils
import multiprocessing
import yaml
from configobj import ConfigObj, flatten_errors
from validate import Validator

sys.path.insert(0,'.')

files = []
for path in args.files:
    if os.path.isdir(path):
        files += utils.all_files_matching(path, '*.root*')
    else:
        files += path.split(',')
args.files = files

if args.metadata.endswith('.yml'):
    with open(args.metadata, 'r') as configfile:
        metadata = yaml.load(configfile)
else:
    configspec = os.path.splitext(args.metadata)[0]+'.spec'
    if not os.path.isfile(configspec):
        sys.exit('%s does not exist' % configspec)
    metadata = ConfigObj(args.metadata, configspec=configspec)
    validator = Validator()
    result = metadata.validate(validator, preserve_errors=True)
    if result != True:
        for entry in flatten_errors(metadata, result):
            # each entry is a tuple
            section_list, key, error = entry
            if key is not None:
                section_list.append(key)
            else:
                section_list.append('[missing section]')
            section_string = ', '.join(section_list)
            if error == False:
                error = 'Missing value or section.'
            print section_string, ' = ', error
        sys.exit(1)

if args.dataset not in metadata:
    sys.exit("dataset %s not defined in metadata!" % args.dataset)
meta = metadata[args.dataset]

fileset = ATLASFileset(
    name = args.dataset,
    title = datasets.labels[meta["label"]],
    label = None,
    datatype = datasets.types[meta["type"]],
    classtype = datasets.classes[meta["class"]],
    treename = meta["tree"],
    weight = meta["weight"],
    files = args.files,
    grl = meta.get('grl', None),
    tags = None,
    meta = None,
    properties = None
)

for key, value in meta.items():
    print '%s = %s' % (key, value)

parent_connection, child_connection = multiprocessing.Pipe()

supervisor = ATLASSupervisor(
    student = args.student,
    outputname = args.dataset,
    files = fileset.files,
    metadata = fileset,
    nstudents = 1,
    connection = child_connection,
    gridmode = True,
    grl = fileset.grl,
    events = args.events,
    options = user_args)

try:
    supervisor.start()
    supervisor.join()
except KeyboardInterrupt, SystemExit:
    print "Cleaning up..."
    parent_connection.send(None)
    supervisor.join()
