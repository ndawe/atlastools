#!/usr/bin/env python

try:
    from argparse import ArgumentParser
except ImportError:
    from rootpy.backports.argparse import ArgumentParser

parser = ArgumentParser(usage="%prog [args] file1,file2,file3...")
parser.add_argument("-v","--verbose", action="store_true",
                  help="verbose", default=False)
parser.add_argument("--grl",
                  help="good runs list", default=None)
parser.add_argument("--events", type=int,
                  help="number of events to process", default=-1)
parser.add_argument("--dataset",
                  help="name of dataset being processed", default=None)
parser.add_argument("--metadata",
                  help="YAML file containing dataset definitions", default="datasets.yml")
parser.add_argument('-s',"--student",
                  help="the file (excluding .py extension) containing a class of the same name inheriting from rootpy.batch.Student", default=None)
parser.add_argument('files', nargs='?')
args, user_args = parser.parse_known_args()

import sys
import os
import ROOT
import glob
from atlastools.batch import ATLASSupervisor
from atlastools import datasets
from atlastools import utils
from rootpy.data.dataset import Fileset
import multiprocessing
import yaml
from configobj import ConfigObj, flatten_errors
from validate import Validator

sys.path.insert(0,'.')

if not args.student:
    sys.exit("Student file not specified!")

if not args.dataset:
    sys.exit("dataset name not specified!")

if not args.metadata:
    sys.exit("metadata file not specified!")

try:
    # remove .py extension if present
    args.student = os.path.splitext(args.student)[0]
    print "importing %s..."% args.student
    exec "from %s import %s"% (args.student, args.student)
except Exception as ex:
    print ex
    sys.exit(1)

if os.path.isdir(args.files):
    args.files = utils.all_files_matching(args.files, '*.root*')
else:
    args.files = args.files.split(',')
if len(args.files) == 0:
    print "No input files specified!"
    sys.exit(1)

if args.metadata.endswith('.yml'):
    with open(args.metadata, 'r') as configfile:
        metadata = yaml.load(configfile)
else:
    configspec = os.path.splitext(args.metadata)[0]+'.spec'
    if not os.path.isfile(configspec):
        sys.exit('%s does not exist' % configspec)
    metadata = ConfigObj(args.metadata, configspec=configspec)
    validator = Validator()
    result = metadata.validate(validator, preserve_errors=True)
    if result != True:
        for entry in flatten_errors(metadata, result):
            # each entry is a tuple
            section_list, key, error = entry
            if key is not None:
                section_list.append(key)
            else:
                section_list.append('[missing section]')
            section_string = ', '.join(section_list)
            if error == False:
                error = 'Missing value or section.'
            print section_string, ' = ', error
        sys.exit(1)

meta = metadata.get(args.dataset, None)
if not meta:
    sys.exit("dataset %s not defined in metadata!"% args.dataset)

fileset = Fileset(
    name = args.dataset,
    title = datasets.labels[meta["label"]],
    label = None,
    datatype = datasets.types[meta["type"]],
    classtype = datasets.classes[meta["class"]],
    treename = meta["tree"],
    weight = meta["weight"],
    files = args.files,
    tags = None,
    meta = None,
    properties = None
)

if args.grl is None and meta.has_key("grl"):
    args.grl = meta["grl"]

supervisor = ATLASSupervisor(
    name = args.student,
    outputname = args.dataset,
    fileset = fileset,
    nstudents = 1,
    process = eval(args.student),
    connect_queue = multiprocessing.Queue(-1),
    gridmode = True,
    grl = args.grl,
    events = args.events,
    options = user_args)

try:
    supervisor.start()
    supervisor.join()
except KeyboardInterrupt, SystemExit:
    print "Cleaning up..."
    supervisor.connect_queue.put(None)
    supervisor.join()
