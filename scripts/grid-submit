#!/usr/bin/env python

from argparse import ArgumentParser

parser = ArgumentParser(usage="%(prog)s [args] samplename1 samplename2 ...")
parser.add_argument('-m', '--meta', dest='metadata',
                    help='YAML file containing dataset metadata',
                    default='datasets.yml')
parser.add_argument('-v', '--version',
                    type=int,
                    help='output dataset version number',
                    default=1)
parser.add_argument('-s', '--student',
                    help='the file (excluding .py extension) containing a '
                         'class of the same name inheriting '
                         'from rootpy.batch.Student', required=True)
parser.add_argument('-u', '--user',
                    help='your grid dataset username i.e. JohnDoe',
                    required=True)
parser.add_argument('--nosite', action='store_true',
                    help='override site in metadata and let the grid decide')
parser.add_argument('-g', '--get', action='store_true',
                  help='download datasets')
parser.add_argument('-d', '--dest', default='.',
                    help='directory in which to download the datasets')
parser.add_argument('--merge', action='store_true',
                  help='merge outputs on the grid')
parser.add_argument('datasets', nargs="+")
args, user_args = parser.parse_known_args()

import yaml
from configobj import ConfigObj, flatten_errors
from validate import Validator
import sys
from subprocess import call
import fnmatch
import os
from glob import glob
import subprocess

if args.metadata.endswith('.yml'):
    with open(args.metadata, 'r') as configfile:
        metadata = yaml.load(configfile)
else:
    configspec = os.path.splitext(args.metadata)[0]+'.spec'
    if not os.path.isfile(configspec):
        sys.exit('%s does not exist' % configspec)
    metadata = ConfigObj(args.metadata, configspec=configspec)
    validator = Validator()
    result = metadata.validate(validator, preserve_errors=True)
    if result != True:
        for entry in flatten_errors(metadata, result):
            # each entry is a tuple
            section_list, key, error = entry
            if key is not None:
                section_list.append(key)
            else:
                section_list.append('[missing section]')
            section_string = ', '.join(section_list)
            if error == False:
                error = 'Missing value or section.'
            print section_string, ' = ', error
        sys.exit(1)

sorted_datasets = sorted(metadata.keys())

# expand globs
datasets = []
for dataset in args.datasets:
    if '*' in dataset:
        datasets += fnmatch.filter(sorted_datasets, dataset)
    else:
        datasets.append(dataset)

if not args.get:
    
    import pkg_resources
    import shutil
    import stat
    filename = 'grid-setup.sh' 
    print "Copying %s from atlastools..." % filename
    setup_script = pkg_resources.resource_filename('atlastools', 'etc/%s' % filename)
    shutil.copyfile(setup_script, filename)
    os.chmod(filename, stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR |\
                       stat.S_IRGRP | stat.S_IROTH)
    subprocess.call('./%s local' % filename, shell=True)

exclude_files = []
extra_files = []
if os.path.isfile('panda.inc'):
    with open('panda.inc') as f:
        for i, line in enumerate(f.readlines()):
            if line.startswith('#'):
                continue
            line = line.strip()
            try:
                op, path = line.split()
            except:
                sys.exit("panda.inc: '%s' not understood on line %i" % (line, i+1))
            if op == 'include':
                files = glob(path)
                for name in files:
                    if name in exclude_files:
                        print "conflict between included %s and excluded %s" % (path, name)
                        print "including %s anyway..." % name
                        files.remove(name)
                extra_files += files
            elif op == 'exclude':
                files = glob(path)
                for name in files:
                    if name in extra_files:
                        print "conflict between included %s and excluded %s" % (name, path)
                        print "including %s anyway..." % name
                        files.remove(name)
                exclude_files += files
            else:
                sys.exit("panda.inc: operation '%s' not understood on line %i" % (op, i+1))

for dataset in datasets:
    if not dataset in metadata:
        sys.exit("dataset %s not defined in metadata %s" % (dataset, args.metadata))
    inDS = metadata[dataset]['container']
    if os.path.isfile(inDS):
        with open(inDS) as f:
            inDS = [s.strip() for s in f.readlines()]
    if type(inDS) is not list:
        inDS = [inDS]
    version = args.version
    # take name of first dataset
    ds_name = inDS[0].strip('/').replace('*','_').replace('merge.NTUP_TAUMEDIUM.','')
    panda_outDS = 'user.%s.%s.%s.v%i' % (args.user, os.path.splitext(args.student)[0], ds_name, version)
    if args.get:
        if not os.path.isdir(args.dest):
            sys.exit("destination path %s does not exist" % args.dest)
        call('cd %s; run -e grid dq2-get -T 3,8 %s/; cd -' % (args.dest, panda_outDS), shell=True)
        continue
    for panda_inDS in inDS:
        panda_site = None
        if ':' in panda_inDS:
            panda_inDS, panda_site = panda_inDS.split(':') 
        panda_bexec = './grid-setup.sh build-packages'
        # `which python` is needed since setuptools rewrites the shebang
        # the sheband specified in the buildjob won't be the same as in the worker job
        panda_exec = 'source grid-setup.sh worker; ' \
                     'python \`which grid-batch\` --dataset %s ' \
                     '--metadata %s --student %s %%IN' % \
                     (dataset, args.metadata, args.student)
        panda_outputs = '%s.root,cutflow.p' % dataset 
        panda_opts = []
        if exclude_files:
            panda_opts.append('--excludeFile %s' % ','.join(exclude_files))
        if extra_files:
            panda_opts.append('--extFile %s' % ','.join(extra_files))
        command = [
            'prun',
            '--bexec "%s"' % panda_bexec,
            '--exec "%s"' % panda_exec,
            '--inDS %s' % panda_inDS,
            '--outDS %s' % panda_outDS,
            '--outputs %s' % panda_outputs
        ] + panda_opts
        if args.merge:
            command += ['--mergeOutput',
                        '--mergeScript "source grid-setup.sh worker; python \`which grid-merge\` -o %OUT -i %IN"']
        if panda_site is not None and '--site' not in user_args and not args.nosite:
            command.append('--site %s' % panda_site)
        command = ' '.join(command)
        if user_args:
            command += ' %s' % ' '.join(user_args)
        print "executing:"
        print command
        call(command, shell=True)

if not args.get:
    subprocess.call('./grid-setup.sh clean', shell=True)
