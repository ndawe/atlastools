#!/usr/bin/env python

try:
    from argparse import ArgumentParser
except ImportError:
    from rootpy.backports.argparse import ArgumentParser

parser = ArgumentParser(usage="%(prog)s [args] samplename1 samplename2 ...")
parser.add_argument('-m', '--meta', dest='metadata',
                    help='YAML file containing dataset metadata',
                    default='datasets.yml')
parser.add_argument('-v', '--version',
                    help='version number/string appended to output dataset name',
                    default='v1')
parser.add_argument('-s', '--student',
                    help='the file (excluding .py extension) containing a '
                         'class of the same name inheriting '
                         'from rootpy.batch.Student', required=True)
parser.add_argument('-u', '--user',
                    help='your grid dataset username i.e. JohnDoe',
                    required=True)
parser.add_argument('--nosite', action='store_true',
                    help='override site in metadata and let the grid decide')
parser.add_argument('-g', '--get', action='store_true',
                  help='download datasets')
parser.add_argument('-d', '--dest', default='.',
                    help='directory in which to download the datasets')
parser.add_argument('--merge', action='store_true',
                  help='merge outputs on the grid')
parser.add_argument('datasets', nargs="+")
args, user_args = parser.parse_known_args()

import yaml
import sys
from subprocess import call
import fnmatch
import os
from glob import glob
import subprocess

metafile = open(args.metadata)
metadata = yaml.load(metafile)
metafile.close()

sorted_datasets = sorted(metadata.keys())

# expand globs
datasets = []
for dataset in args.datasets:
    if '*' in dataset:
        datasets += fnmatch.filter(sorted_datasets, dataset)
    else:
        datasets.append(dataset)

exclude_files = []
extra_files = []
if os.path.isfile('.pandaconfig'):
    with open('.pandaconfig') as f:
        for i, line in enumerate(f.readlines()):
            if line.startswith('#'):
                continue
            line = line.strip()
            try:
                op, path = line.split()
            except:
                sys.exit(".pandaconfig: '%s' not understood on line %i" % (line, i+1))
            if op == 'include':
                files = glob(path)
                for name in files:
                    if name in exclude_files:
                        print "conflict between included %s and excluded %s" % (path, name)
                        print "including %s anyway..." % name
                        files.remove(name)
                extra_files += files
            elif op == 'exclude':
                files = glob(path)
                for name in files:
                    if name in extra_files:
                        print "conflict between included %s and excluded %s" % (name, path)
                        print "including %s anyway..." % name
                        files.remove(name)
                exclude_files += files
            else:
                sys.exit(".pandaconfig: operation '%s' not understood on line %i" % (op, i+1))

if not os.path.exists('grid-setup.sh'):
    print "Copying grid-setup.sh from atlastools..."
    import pkg_resources
    import shutil
    import stat
    setup_script = pkg_resources.resource_filename('atlastools', 'etc/grid-setup.sh')
    shutil.copyfile(setup_script, './grid-setup.sh')
    os.chmod('./grid-setup.sh', stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR |\
                                stat.S_IRGRP | stat.S_IROTH)

subprocess.call('./grid-setup.sh local', shell=True)

for dataset in datasets:
    if not dataset in metadata:
        sys.exit("dataset %s not defined in metadata %s" % (dataset, args.metadata))
    panda_outDS = 'user.%s.%s.%s.%s' % (args.user, os.path.splitext(args.student)[0], dataset, args.version)
    if args.get:
        if not os.path.isdir(args.dest):
            sys.exit("destination path %s does not exist" % args.dest)
        call('cd %s; run -e grid dq2-get -T 3,8 %s/; cd -' % (args.dest, panda_outDS), shell=True)
        continue
    inDS = metadata[dataset]['container']
    if type(inDS) is not list:
        inDS = [inDS]
    for panda_inDS in inDS:
        panda_site = None
        if ':' in panda_inDS:
            panda_inDS, panda_site = panda_inDS.split(':') 
        panda_bexec = './setup.sh build'
        panda_exec = 'source setup.sh worker; ' \
                     'grid-batch --dataset %s ' \
                     '--metadata %s --student %s %%IN' % \
                     (dataset, args.metadata, args.student)
        panda_outputs = '%s.root,cutflow.p' % dataset 
        panda_opts = []
        if exclude_files:
            panda_opts.append('--excludeFile %s' % ','.join(exclude_files))
        if extra_files:
            panda_opts.append('--extFile %s' % ','.join(extra_files))
        command = [
            'prun',
            '--bexec "%s"' % panda_bexec,
            '--exec "%s"' % panda_exec,
            '--inDS %s' % panda_inDS,
            '--outDS %s' % panda_outDS,
            '--outputs %s' % panda_outputs
        ] + panda_opts
        if args.merge:
            command += ['--mergeOutput', '--mergeScript grid-merge']
        if panda_site is not None and '--site' not in user_args and not args.nosite:
            command.append('--site %s' % panda_site)
        command = ' '.join(command)
        if user_args:
            command += ' %s' % ' '.join(user_args)
        print "executing:"
        print command
        call(command, shell=True)

subprocess.call('./grid-setup.sh clean')
